{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предлагается начать разбираться с задачей анализа тональности отзывов на примере сентимент-анализа отзывов на фильмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Цифра-2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = negfeats + posfeats\n",
    "classes = np.append(np.zeros(len(negfeats)), np.ones(len(posfeats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подсчитайте количество отзывов в выборке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "ans_1 = classes.shape[0]\n",
    "print(ans_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Подсчитайте долю класса 1 в выборке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "ans_2 = len(posfeats) / ans_1\n",
    "print(ans_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_str = list(map(lambda x: \" \".join(x), all_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "vect_repr = count_vec.fit_transform(all_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x39659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 666842 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_3 = 39659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8360216503929078\n"
     ]
    }
   ],
   "source": [
    "ans_4 = np.mean(cross_val_score(pipe, all_str, classes, cv=3))\n",
    "print(ans_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Аналогично accuracy, оцените качество по ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9107764937833774\n"
     ]
    }
   ],
   "source": [
    "ans_5 = np.mean(cross_val_score(pipe, all_str, classes, cv=3, scoring='roc_auc'))\n",
    "print(ans_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Обучите логистическую регрессию на всей доступной вам выборке и выведите два наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vect = CountVectorizer().fit(all_str)\n",
    "cls = LogisticRegression().fit(c_vect.transform(all_str), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = cls.coef_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.7822544710446759, -0.6366239501417396],\n",
       " [0.44416042537462447, 0.5560506991496287])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(coeffs)[:2], sorted(coeffs)[-2:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad unfortunately'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_2 = sorted(coeffs)[:2]\n",
    "ans_6 = \" \".join([c_vect.get_feature_names()[list(coeffs).index(i)] for i in top_2])\n",
    "ans_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество (.mean()) и стандартное отклонение (.std()) по fold'ам для:\n",
    "\n",
    "    а) pipeline из CountVectorizer() и LogisticRegression(), \n",
    "    б) pipeline из TfidfVectorizer() и LogisticRegression(). \n",
    "\n",
    "В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans(ans, n_task):\n",
    "    with open('answer_' + str(n_task) + '.txt', 'w') as f:\n",
    "        f.write(str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv_lr_1 = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_tf_lr_1 = Pipeline([\n",
    "    ('count_vect', TfidfVectorizer()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние значения и стандартные отклонинея для CountVectorizer, TfidfVectorizer: 0.8415000000000001 0.01677796173556255 0.8210000000000001 0.004062019202317978\n"
     ]
    }
   ],
   "source": [
    "cv = 5\n",
    "\n",
    "a_ans = cross_val_score(pipe_cv_lr_1, all_str, classes, cv=cv)\n",
    "b_ans = cross_val_score(pipe_tf_lr_1, all_str, classes, cv=cv)\n",
    "\n",
    "ans = (a_ans.mean(), a_ans.std(), b_ans.mean(), b_ans.std())\n",
    "ans_2_1 = \" \".join([str(i) for i in ans])\n",
    "write_ans(ans_2_1, 1)\n",
    "print('Средние значения и стандартные отклонинея для CountVectorizer, TfidfVectorizer:', ans_2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Попробуйте задавать разные значения параметра min_df у CountVectorizer. Оцените качество вашего классификатора с min_df=10 и с min_df=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество работы при разных параметрах min_df CountVectorizer: 0.8390000000000001 0.813\n"
     ]
    }
   ],
   "source": [
    "ans = np.array([])\n",
    "for i in [10, 50]:\n",
    "    pipe_cv_lr_2 = Pipeline([\n",
    "        ('count_vect', CountVectorizer(min_df=i)),\n",
    "        ('log_reg', LogisticRegression())\n",
    "    ])\n",
    "    ans = np.append(ans, np.mean(\n",
    "        cross_val_score(pipe_cv_lr_2, all_str, classes, cv=cv)\n",
    "    ))\n",
    "    \n",
    "ans_2_2 = \" \".join([str(i) for i in ans])\n",
    "\n",
    "write_ans(ans_2_2, 2)\n",
    "print('Качество работы при разных параметрах min_df CountVectorizer:', ans_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Попробуйте использовать разные классификаторы после CountVectorizer. И vectorizer, и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество работы худшего из классификаторов (LogisticRegression, LinearSVC, SGDClassifier): 0.7004999999999999\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in ([LogisticRegression(), LinearSVC(), SGDClassifier(random_state=0)]):\n",
    "    pipe_cv_lr_3 = Pipeline([\n",
    "        ('count_vect', CountVectorizer()),\n",
    "        ('log_reg', i)\n",
    "    ])\n",
    "    ans = np.append(ans, np.mean(cross_val_score(pipe_cv_lr_3, all_str, classes, cv=cv)))\n",
    "\n",
    "ans_2_3 = min(ans)\n",
    "write_ans(ans_2_3, 3)\n",
    "print('Качество работы худшего из классификаторов (LogisticRegression, LinearSVC, SGDClassifier):',\n",
    "      ans_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Цифра-2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество работы CountVectorizer при использовании стоп-слов: 0.841 0.8385\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in [CountVectorizer(stop_words=stop_words), CountVectorizer(stop_words='english')]:\n",
    "    pipe_cv_lr_4 = Pipeline([\n",
    "        ('count_vect', i),\n",
    "        ('log_reg', LogisticRegression())\n",
    "    ])\n",
    "    ans = np.append(ans, np.mean(cross_val_score(pipe_cv_lr_4, all_str, classes, cv=cv)))\n",
    "\n",
    "ans_2_4 = \" \".join([str(i) for i in ans])\n",
    "write_ans(ans_2_4, 4)\n",
    "print('Качество работы CountVectorizer при использовании стоп-слов:', ans_2_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество работы CountVectorizer при униграммах и биграммах и буквенных n-граммах: 0.8525 0.82\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in [CountVectorizer(ngram_range=(1, 2)), CountVectorizer(ngram_range=(3,5), analyzer='char_wb')]:\n",
    "    pipe_cv_lr_5 = Pipeline([\n",
    "        ('count_vect', i),\n",
    "        ('log_reg', LogisticRegression())\n",
    "    ])\n",
    "    ans = np.append(ans, np.mean(cross_val_score(pipe_cv_lr_5, all_str, classes, cv=cv)))\n",
    "\n",
    "ans_2_5 = \" \".join([str(i) for i in ans])\n",
    "write_ans(ans_2_5, 5)\n",
    "print('Качество работы CountVectorizer при униграммах и биграммах и буквенных n-граммах:', ans_2_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
